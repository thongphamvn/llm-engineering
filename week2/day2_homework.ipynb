{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb4aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# test the connection\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "# )\n",
    "\n",
    "# print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4b7b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub - waydabber/BetterDisplay: Unlock your displays on your Mac! Flexible HiDPI scaling, XDR/HDR extra brightness, virtual screens, DDC control, extra dimming, PIP/streaming, EDID override and lots more!\n",
      "\n",
      "Skip to content\n",
      "Navigation Menu\n",
      "Toggle navigation\n",
      "Sign in\n",
      "Appearance settings\n",
      "Platform\n",
      "AI CODE CREATION\n",
      "GitHub Copilot\n",
      "Write better code with AI\n",
      "GitHub Spark\n",
      "Build and deploy intelligent apps\n",
      "GitHub Models\n",
      "Manage and compare prompts\n",
      "MCP Registry\n",
      "New\n",
      "Integrate external tools\n",
      "DEVELOPER WORKFLOWS\n",
      "Actions\n",
      "Automate any workflow\n",
      "Codespaces\n",
      "Instant dev environments\n",
      "Issues\n",
      "Plan and track work\n",
      "Code Review\n",
      "Manage code changes\n",
      "APPLICATION SECURITY\n",
      "GitHub Advanced Security\n",
      "Find and fix vulnerabilities\n",
      "Code security\n",
      "Secure your code as you build\n",
      "Secret protection\n",
      "Stop leaks before they start\n",
      "EXPLORE\n",
      "Why GitHub\n",
      "Documentation\n",
      "Blog\n",
      "Changelog\n",
      "Marketplace\n",
      "View all features\n",
      "Solutions\n",
      "BY COMPANY SIZE\n",
      "Enterprises\n",
      "Small and medium teams\n",
      "Startups\n",
      "Nonprofits\n",
      "BY USE CASE\n",
      "App Modernization\n",
      "DevSecOps\n",
      "DevOps\n",
      "CI/CD\n",
      "View all use cases\n",
      "BY INDUSTRY\n",
      "Healthcare\n",
      "Financial services\n",
      "Manufacturing\n",
      "Government\n",
      "View all industries\n",
      "View all solutions\n",
      "Resources\n",
      "EXPLORE BY TOPIC\n",
      "AI\n",
      "Software Development\n",
      "DevOps\n",
      "Security\n",
      "View all topics\n",
      "EXPLORE BY TYPE\n",
      "Customer stories\n",
      "Events & webinars\n",
      "Ebooks & reports\n",
      "Business insights\n",
      "GitHub Skills\n",
      "SUPPORT & SERVICES\n",
      "Documentation\n",
      "Customer support\n",
      "Community forum\n",
      "Trust center\n",
      "Partners\n",
      "Open Source\n",
      "COMMUNITY\n",
      "GitHub Sponsors\n",
      "Fund open source developers\n",
      "PROGRAMS\n",
      "Security Lab\n",
      "Maintainer Community\n",
      "Accelerator\n",
      "Archive Program\n",
      "REPOSITORIES\n",
      "Topics\n",
      "Trending\n",
      "Collections\n",
      "Enterprise\n",
      "ENTERPRISE SOLUTIONS\n",
      "Enterprise platform\n",
      "AI-powered developer platform\n",
      "AVAILABLE ADD-ONS\n",
      "GitHub Advanced Security\n",
      "Enterprise-grade security features\n",
      "Copilot for Business\n",
      "Enterprise-grade AI features\n",
      "Premium Support\n",
      "Enterprise-grade 24/7 support\n",
      "Pricing\n",
      "Search or jump to...\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "Search\n",
      "Clear\n",
      "Search syntax tips\n",
      "Provide feedback\n",
      "We read every piece of feed\n"
     ]
    }
   ],
   "source": [
    "from scraper import fetch_website_contents\n",
    "\n",
    "content = fetch_website_contents(\"https://github.com/waydabber/BetterDisplay?tab=readme-ov-file\")\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff117720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7880\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1635, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 760, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 751, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 734, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 898, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/bp/j1s2v61n4xx59qhdtzrk1rbm0000gp/T/ipykernel_26862/3951055809.py\", line 49, in stream_brochure\n",
      "    yield from resp\n",
      "  File \"/var/folders/bp/j1s2v61n4xx59qhdtzrk1rbm0000gp/T/ipykernel_26862/3951055809.py\", line 22, in stream_claude\n",
      "    text_resp = client.chat.completions.create(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/thong.pham/Documents/thong/llm-engineering/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `claude-3-haiku-20240307` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "system_message = \"\"\"\n",
    "You are an assistant that analyzes the contents of a company website landing page\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "\"\"\"\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    text_resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    final_text = \"\"\n",
    "\n",
    "    for chunk in text_resp:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            final_text += chunk.choices[0].delta.content\n",
    "            yield final_text\n",
    "\n",
    "def stream_claude(prompt):\n",
    "    text_resp = client.chat.completions.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    final_text = \"\"\n",
    "\n",
    "    for chunk in text_resp:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            final_text += chunk.choices[0].delta.content\n",
    "            yield final_text\n",
    "\n",
    "def stream_with_model(prompt, model):\n",
    "    if model == \"GPT\":\n",
    "        return stream_gpt(prompt)\n",
    "    elif model == \"Claude\":\n",
    "        return stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model\")\n",
    "\n",
    "\n",
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += fetch_website_contents(url)\n",
    "    \n",
    "    resp = stream_with_model(prompt, model)\n",
    "    yield from resp\n",
    "\n",
    "\n",
    "# using gradio to create a web interface\n",
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[gr.Textbox(label=\"Company name\"), gr.Textbox(label=\"URL\"), gr.Dropdown(choices=[\"GPT\", \"Claude\"], value=\"GPT\")],\n",
    "    outputs=gr.Markdown(label=\"Brochure\"),\n",
    "    title=\"Brochure Generator\",\n",
    "    description=\"Generate a brochure for a company based on their landing page.\",\n",
    "    examples=[\n",
    "        [\"Hugging Face\", \"https://huggingface.co\"],\n",
    "        [\"Edward Donner\", \"https://edwarddonner.com\"]\n",
    "    ]\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
